#!/usr/bin/env node

/**
 * GitHub PR Activity Fetcher
 *
 * ÌäπÏ†ï organizationÏóêÏÑú ÏÇ¨Ïö©ÏûêÏùò PR ÌôúÎèôÏùÑ Ï£ºÍ∞ÑÎ≥ÑÎ°ú Ï†ïÎ¶¨
 *
 * ÏÇ¨Ïö©Î≤ï:
 * node fetch-github-prs.js --token=ghp-xxx --org=organization --emails=joon@daangn.com,dnjswns0930@gmail.com --year=2025
 *
 * ÌïÑÏöîÌïú scope: repo (private repo Ï†ëÍ∑º Ïãú)
 */

const https = require('https')
const fs = require('fs')

// CLI Ïù∏Ïûê ÌååÏã±
function getArg(name) {
  const arg = process.argv.find((a) => a.startsWith(`--${name}=`))
  return arg ? arg.split('=').slice(1).join('=') : undefined
}

const TOKEN = process.env.GITHUB_TOKEN || getArg('token')
const ORG = process.env.GITHUB_ORG || getArg('org')
const EMAILS = (process.env.GITHUB_EMAILS || getArg('emails') || '').split(',').filter(Boolean)
const YEAR = parseInt(process.env.YEAR || getArg('year'), 10)
const CONCURRENCY = parseInt(process.env.CONCURRENCY || getArg('concurrency') || '3', 10)
// GitHub Enterprise Server ÏßÄÏõê: Í∏∞Î≥∏Í∞íÏùÄ github.com
const API_BASE = (process.env.GITHUB_API_URL || getArg('api-url') || 'https://api.github.com').replace(/\/$/, '')

// ÏûÖÎ†• Í≤ÄÏ¶ù
if (!TOKEN || !ORG || EMAILS.length === 0 || !YEAR) {
  console.error(`
Usage: node fetch-github-prs.js --token=<github-token> --org=<org-name> --emails=<email1,email2> --year=<year>

Options:
  --token       GitHub Personal Access Token (env: GITHUB_TOKEN)
  --org         GitHub Organization name (env: GITHUB_ORG)
  --emails      Comma-separated email addresses (env: GITHUB_EMAILS)
  --year        Year to search (env: YEAR)
  --concurrency Concurrent requests (default: 3, env: CONCURRENCY)
  --api-url     GitHub API URL (default: https://api.github.com, env: GITHUB_API_URL)
                For Enterprise Server: https://<hostname>/api/v3

Example:
  node fetch-github-prs.js --token=ghp_xxx --org=organization --emails=joon@daangn.com,dnjswns0930@gmail.com --year=2025

  # GitHub Enterprise Server
  node fetch-github-prs.js --api-url=https://github.example.com/api/v3 --token=xxx --org=my-org --emails=user@example.com --year=2025
`)
  process.exit(1)
}

// ÌÉÄÏù¥Î®∏
const timer = {
  start: null,
  lap(label) {
    const now = Date.now()
    const elapsed = this.start ? ((now - this.start) / 1000).toFixed(2) : '0.00'
    console.log(`[${elapsed}s] ${label}`)
  },
  begin() {
    this.start = Date.now()
    this.lap('Started')
  },
  end() {
    this.lap('Completed')
    const total = ((Date.now() - this.start) / 1000).toFixed(2)
    console.log(`\nTotal time: ${total}s`)
  },
}

// ÎèôÏãúÏÑ± Ï†úÌïú Ïã§ÌñâÍ∏∞
async function runWithConcurrency(items, concurrency, fn) {
  const results = []
  const executing = new Set()

  for (const item of items) {
    const promise = Promise.resolve().then(() => fn(item))
    results.push(promise)
    executing.add(promise)

    const cleanup = () => executing.delete(promise)
    promise.then(cleanup, cleanup)

    if (executing.size >= concurrency) {
      await Promise.race(executing)
    }
  }

  return Promise.all(results)
}

// GitHub API Ìò∏Ï∂ú Ìó¨Ìçº
const MAX_RETRIES = 3
const RETRY_DELAY = 2000

function githubApiOnce(path, options = {}) {
  return new Promise((resolve, reject) => {
    const url = path.startsWith('https://') ? new URL(path) : new URL(`${API_BASE}${path}`)

    const req = https.get(
      url.toString(),
      {
        headers: {
          Authorization: `Bearer ${TOKEN}`,
          Accept: 'application/vnd.github.v3+json',
          'User-Agent': 'fetch-github-prs',
          ...options.headers,
        },
        timeout: 30000,
      },
      (res) => {
        let data = ''
        res.on('data', (chunk) => (data += chunk))
        res.on('end', () => {
          try {
            // Rate limit Ï≤¥ÌÅ¨
            const remaining = res.headers['x-ratelimit-remaining']
            if (remaining && parseInt(remaining, 10) < 100) {
              console.log(`\n‚ö†Ô∏è  Rate limit remaining: ${remaining}`)
            }

            const json = JSON.parse(data)

            if (res.statusCode >= 400) {
              reject(new Error(`GitHub API Error (${res.statusCode}): ${json.message || data}`))
            } else {
              // Link Ìó§ÎçîÏóêÏÑú Îã§Ïùå ÌéòÏù¥ÏßÄ URL Ï∂îÏ∂ú
              const linkHeader = res.headers.link
              let nextUrl = null
              if (linkHeader) {
                const nextMatch = linkHeader.match(/<([^>]+)>;\s*rel="next"/)
                if (nextMatch) nextUrl = nextMatch[1]
              }

              resolve({ data: json, nextUrl })
            }
          } catch (e) {
            reject(new Error(`JSON parse error: ${e.message}`))
          }
        })
      }
    )

    req.on('error', (e) => reject(new Error(`Network error: ${e.message}`)))
    req.on('timeout', () => {
      req.destroy()
      reject(new Error('Request timeout (30s)'))
    })
  })
}

async function githubApi(path, options = {}, context = '', skipRetry = false) {
  let lastError

  const maxAttempts = skipRetry ? 1 : MAX_RETRIES

  for (let attempt = 1; attempt <= maxAttempts; attempt++) {
    try {
      return await githubApiOnce(path, options)
    } catch (e) {
      lastError = e

      if (skipRetry) {
        throw e
      }

      const contextStr = context ? ` [${context}]` : ''

      if (attempt < maxAttempts) {
        console.log(`\n‚ö†Ô∏è  ${path}${contextStr} failed (attempt ${attempt}/${maxAttempts}): ${e.message}`)
        console.log(`   Retrying in ${RETRY_DELAY / 1000}s...`)
        await new Promise((r) => setTimeout(r, RETRY_DELAY))
      } else {
        console.log(`\n‚ùå ${path}${contextStr} failed after ${maxAttempts} attempts: ${e.message}`)
      }
    }
  }

  throw lastError
}

// ÌéòÏù¥ÏßÄÎÑ§Ïù¥ÏÖò Ï≤òÎ¶¨ÌïòÏó¨ Î™®Îì† Í≤∞Í≥º Í∞ÄÏ†∏Ïò§Í∏∞
async function githubApiAll(path, context = '', skipRetry = false, extraHeaders = {}) {
  const allData = []
  let url = path

  while (url) {
    const { data, nextUrl } = await githubApi(url, { headers: extraHeaders }, context, skipRetry)
    if (Array.isArray(data)) {
      allData.push(...data)
    } else if (data.items) {
      allData.push(...data.items)
    }
    url = nextUrl
    if (nextUrl) await new Promise((r) => setTimeout(r, 100)) // Rate limit Î∞©ÏßÄ
  }

  return allData
}

// Organization ÎòêÎäî UserÏùò Î™®Îì† Î†àÌè¨ÏßÄÌÜ†Î¶¨ Ï°∞Ìöå
async function getRepos(owner) {
  console.log(`\nFetching repositories for ${owner}...`)

  // Î®ºÏ†Ä OrganizationÏúºÎ°ú ÏãúÎèÑ (Ïû¨ÏãúÎèÑ ÏóÜÏù¥ ÌïúÎ≤àÎßå)
  try {
    const repos = await githubApiAll(`/orgs/${owner}/repos?per_page=100&type=all`, 'org repos', true)
    console.log(`Found ${repos.length} repositories (organization)`)
    return repos
  } catch (e) {
    if (!e.message.includes('404')) {
      throw e
    }
    // 404Î©¥ UserÎ°ú fallback
  }

  // OrganizationÏù¥ ÏïÑÎãàÎ©¥ UserÎ°ú ÏãúÎèÑ
  try {
    const repos = await githubApiAll(`/users/${owner}/repos?per_page=100&type=all`, 'user repos')
    console.log(`Found ${repos.length} repositories (user)`)
    return repos
  } catch (e) {
    if (e.message.includes('404')) {
      throw new Error(`"${owner}" is not a valid GitHub organization or user`)
    }
    throw e
  }
}

// Search APIÎ°ú Ïù¥Î©îÏùº Í∏∞Î∞ò Ïª§Î∞ã Í≤ÄÏÉâ (Ï†ÑÏ≤¥ orgÏóêÏÑú ÌïúÎ≤àÏóê)
async function searchCommitsByEmail(org, email, year) {
  const query = `author-email:${email} org:${org} committer-date:${year}-01-01..${year}-12-31`

  try {
    const commits = await githubApiAll(
      `/search/commits?q=${encodeURIComponent(query)}&per_page=100`,
      `commits/${email}`,
      false,
      { Accept: 'application/vnd.github.cloak-preview+json' }
    )
    return commits
  } catch (e) {
    // Search API Ïã§Ìå®Ïãú Îπà Î∞∞Ïó¥ Î∞òÌôò
    console.log(`\n‚ö†Ô∏è  Commit search failed for ${email}: ${e.message}`)
    return []
  }
}

// Ïª§Î∞ãÏù¥ ÏÜçÌïú PR Ï°∞Ìöå
async function getPRsForCommit(repo, sha) {
  try {
    const { data } = await githubApi(
      `/repos/${ORG}/${repo}/commits/${sha}/pulls`,
      { headers: { Accept: 'application/vnd.github.v3+json' } },
      `${repo}/${sha.substring(0, 7)}`
    )
    return data
  } catch (e) {
    return []
  }
}

// Ï£ºÏ∞® Í≥ÑÏÇ∞
function getWeekNumber(date) {
  const d = new Date(date)
  const startOfYear = new Date(d.getFullYear(), 0, 1)
  const days = Math.floor((d - startOfYear) / (24 * 60 * 60 * 1000))
  return Math.ceil((days + startOfYear.getDay() + 1) / 7)
}

// Ï£ºÍ∞Ñ Î≤îÏúÑ Î¨∏ÏûêÏó¥
function getWeekRange(year, week) {
  const startOfYear = new Date(year, 0, 1)
  const daysOffset = (week - 1) * 7 - startOfYear.getDay()
  const weekStart = new Date(year, 0, 1 + daysOffset)
  const weekEnd = new Date(weekStart)
  weekEnd.setDate(weekEnd.getDate() + 6)

  const format = (d) => `${d.getMonth() + 1}/${d.getDate()}`
  return `${format(weekStart)} - ${format(weekEnd)}`
}

// ÎßàÌÅ¨Îã§Ïö¥ ÏÉùÏÑ±
function generateMarkdown(prs, org, year) {
  // Ï£ºÍ∞ÑÎ≥ÑÎ°ú Í∑∏Î£πÌôî
  const weeklyData = {}

  for (const pr of prs) {
    const createdAt = new Date(pr.created_at)
    const week = getWeekNumber(createdAt)
    const weekKey = `${year}-W${week.toString().padStart(2, '0')}`

    if (!weeklyData[weekKey]) {
      weeklyData[weekKey] = { week, repos: {} }
    }

    const repoName = pr.base.repo.name
    if (!weeklyData[weekKey].repos[repoName]) {
      weeklyData[weekKey].repos[repoName] = []
    }

    weeklyData[weekKey].repos[repoName].push(pr)
  }

  let md = `# ${org}Ïùò ${year}ÎÖÑ GitHub PR ÌôúÎèô\n\n`
  md += `> Í≤ÄÏÉâ Ïù¥Î©îÏùº: ${EMAILS.join(', ')}\n`
  md += `> ÏÉùÏÑ±Ïùº: ${new Date().toLocaleDateString('ko-KR')}\n\n`
  md += `---\n\n`

  const sortedWeeks = Object.keys(weeklyData).sort()

  if (sortedWeeks.length === 0) {
    md += `ÌôúÎèô ÎÇ¥Ïó≠Ïù¥ ÏóÜÏäµÎãàÎã§.\n`
    return md
  }

  // ÏöîÏïΩ ÌÜµÍ≥Ñ
  const totalPRs = prs.length
  const mergedPRs = prs.filter((pr) => pr.merged_at).length
  const repoSet = new Set(prs.map((pr) => pr.base.repo.name))

  md += `## ÏöîÏïΩ\n\n`
  md += `- **Ï¥ù PR Ïàò**: ${totalPRs}Í∞ú\n`
  md += `- **Merged PR**: ${mergedPRs}Í∞ú\n`
  md += `- **ÌôúÎèô Î†àÌè¨ÏßÄÌÜ†Î¶¨**: ${repoSet.size}Í∞ú\n`
  md += `- **ÌôúÎèô Ï£ºÏ∞®**: ${sortedWeeks.length}Ï£º\n\n`
  md += `---\n\n`

  for (const weekKey of sortedWeeks) {
    const { week, repos } = weeklyData[weekKey]
    const weekRange = getWeekRange(year, week)

    md += `## ${weekKey} (${weekRange})\n\n`

    for (const repoName of Object.keys(repos).sort()) {
      const repoPRs = repos[repoName]
      md += `### ${repoName}\n\n`

      for (const pr of repoPRs) {
        const status = pr.merged_at ? '‚úÖ Merged' : pr.state === 'closed' ? '‚ùå Closed' : 'üü° Open'
        const createdDate = new Date(pr.created_at).toLocaleDateString('ko-KR', {
          month: 'short',
          day: 'numeric',
        })

        md += `- **[#${pr.number}](${pr.html_url})** ${pr.title}\n`
        md += `  - ${status} | ${createdDate} ÏÉùÏÑ±`

        if (pr.merged_at) {
          const mergedDate = new Date(pr.merged_at).toLocaleDateString('ko-KR', {
            month: 'short',
            day: 'numeric',
          })
          md += ` | ${mergedDate} Î≥ëÌï©`
        }

        md += `\n`

        // PR bodyÍ∞Ä ÏûàÏúºÎ©¥ Ï≤´ Ï§ÑÎßå ÌëúÏãú
        if (pr.body) {
          const firstLine = pr.body.split('\n')[0].trim().substring(0, 100)
          if (firstLine) {
            md += `  - > ${firstLine}${pr.body.length > 100 ? '...' : ''}\n`
          }
        }
      }

      md += '\n'
    }

    md += `---\n\n`
  }

  return md
}

// Î©îÏù∏
async function main() {
  console.log('=== GitHub PR Activity Fetcher ===\n')
  if (API_BASE !== 'https://api.github.com') {
    console.log(`API URL: ${API_BASE}`)
  }
  console.log(`Organization: ${ORG}`)
  console.log(`Emails: ${EMAILS.join(', ')}`)
  console.log(`Year: ${YEAR}`)
  console.log(`Concurrency: ${CONCURRENCY}`)

  timer.begin()

  try {
    const prMap = new Map() // PR Ï§ëÎ≥µ Ï†úÍ±∞Ïö©
    const usernames = new Set()

    // 1. Search Commits APIÎ°ú Ïù¥Î©îÏùº Í∏∞Î∞ò Ïª§Î∞ã Í≤ÄÏÉâ (Ï†ÑÏ≤¥ org ÌïúÎ≤àÏóê)
    console.log(`\nSearching commits by email using Search API...`)

    for (const email of EMAILS) {
      console.log(`\nSearching: ${email}`)
      const commits = await searchCommitsByEmail(ORG, email, YEAR)
      console.log(`Found ${commits.length} commits`)

      // Ïª§Î∞ãÏóêÏÑú username ÏàòÏßë
      for (const commit of commits) {
        if (commit.author?.login) {
          usernames.add(commit.author.login)
        }
      }

      // Í∞Å Ïª§Î∞ãÏù¥ ÏÜçÌïú PR Ï°∞Ìöå
      let processed = 0
      await runWithConcurrency(commits, CONCURRENCY, async (commit) => {
        const repoName = commit.repository?.name || commit.url?.match(/repos\/[^/]+\/([^/]+)/)?.[1]
        if (repoName) {
          const prs = await getPRsForCommit(repoName, commit.sha)
          for (const pr of prs) {
            const createdAt = new Date(pr.created_at)
            if (createdAt.getFullYear() === YEAR) {
              prMap.set(pr.id, pr)
              // pr.userÎäî PR ÏûëÏÑ±ÏûêÏù¥ÎØÄÎ°ú username ÏàòÏßëÏóêÏÑú Ï†úÏô∏
              // (Îã§Î•∏ ÏÇ¨Îûå PRÏóê ÎÇ¥ Ïª§Î∞ãÏù¥ Ìè¨Ìï®Îêú Í≤ΩÏö∞ ÏûòÎ™ªÎêú usernameÏù¥ Ï∂îÍ∞ÄÎê®)
            }
          }
        }
        processed++
        process.stdout.write(`\rFetching PRs: ${processed}/${commits.length} commits | Found ${prMap.size} PRs`)
      })
      console.log('')
    }

    timer.lap(`Collected ${prMap.size} PRs from commits`)

    // 2. authorÎ°úÎèÑ ÏßÅÏ†ë PR Í≤ÄÏÉâ (Ïª§Î∞ã Í∏∞Î∞ò Í≤ÄÏÉâÏùÑ Î≥¥ÏôÑ)
    console.log(`\nSearching PRs by author...`)

    if (usernames.size > 0) {
      console.log(`Found usernames: ${[...usernames].join(', ')}`)

      // Search APIÎ°ú Ìï¥Îãπ ÏÇ¨Ïö©ÏûêÏùò PR Í≤ÄÏÉâ
      for (const username of usernames) {
        try {
          const searchQuery = `type:pr author:${username} org:${ORG} created:${YEAR}-01-01..${YEAR}-12-31`
          const searchResults = await githubApiAll(
            `/search/issues?q=${encodeURIComponent(searchQuery)}&per_page=100`,
            `search/${username}`
          )

          const newPRs = searchResults.filter((item) => item.pull_request && !prMap.has(item.id))
          console.log(`\n@${username}: ${searchResults.length} PRs found, ${newPRs.length} new`)

          let fetched = 0
          for (const item of newPRs) {
            try {
              const { data: pr } = await githubApi(item.pull_request.url, {}, `PR #${item.number}`)
              prMap.set(pr.id, pr)
            } catch (e) {
              // PR ÏÉÅÏÑ∏ Ï°∞Ìöå Ïã§Ìå®Ïãú Í∏∞Î≥∏ Ï†ïÎ≥¥ ÏÇ¨Ïö©
              prMap.set(item.id, {
                ...item,
                base: { repo: { name: item.repository_url.split('/').pop() } },
              })
            }
            fetched++
            process.stdout.write(`\rFetching PR details: ${fetched}/${newPRs.length}`)
          }
          if (newPRs.length > 0) console.log('')
        } catch (e) {
          console.log(`\n‚ö†Ô∏è  Search for ${username} failed: ${e.message}`)
        }
      }
    } else {
      console.log('No usernames found from commits')
    }

    timer.lap(`Total ${prMap.size} unique PRs found`)

    // 4. PR Ï†ïÎ†¨ (ÏÉùÏÑ±Ïùº Í∏∞Ï§Ä)
    const prs = Array.from(prMap.values()).sort(
      (a, b) => new Date(a.created_at) - new Date(b.created_at)
    )

    if (prs.length === 0) {
      console.log('\nNo PRs found.')
      timer.end()
      return
    }

    // 5. ÎßàÌÅ¨Îã§Ïö¥ ÏÉùÏÑ± Î∞è Ï†ÄÏû•
    timer.lap('Generating markdown...')
    const markdown = generateMarkdown(prs, ORG, YEAR)
    const outputPath = `github-prs-${ORG}-${YEAR}.md`

    fs.writeFileSync(outputPath, markdown, 'utf8')
    timer.lap(`Saved to: ${outputPath}`)
    timer.end()
  } catch (error) {
    console.error('\nError:', error.message)
    process.exit(1)
  }
}

main()
